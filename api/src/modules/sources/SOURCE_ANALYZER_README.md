# ðŸ” SourceAnalyzer - Module d'Analyse Automatique des Sources

Un module robuste et extensible pour analyser automatiquement les URLs et dÃ©terminer la meilleure stratÃ©gie de collecte de mentions.

## ðŸŽ¯ Objectifs

- **Analyser** automatiquement une URL pour dÃ©terminer sa scrappabilitÃ©
- **DÃ©tecter** les blocages (Cloudflare, reCAPTCHA, WAF, JavaScript-only)
- **Recommander** la meilleure stratÃ©gie de collecte
- **CrÃ©er** automatiquement des sources sans intervention manuelle
- **Logger** chaque Ã©tape pour un debugging facile
- **Respecter** la lÃ©galitÃ© (robots.txt, pas de contournement)

## ðŸ“‹ StratÃ©gies SupportÃ©es

### 1. **SCRAPABLE** âœ…
L'URL peut Ãªtre scrappÃ©e directement avec Cheerio/Playwright.

**Conditions:**
- HTML valide disponible
- Pas de blocage dÃ©tectÃ©
- robots.txt permet le scraping
- Pas JavaScript-only

**Exemple:**
```json
{
  "strategy": "SCRAPABLE",
  "message": "Cette source peut Ãªtre scrappÃ©e directement.",
  "suggestedSourceType": "BLOG",
  "suggestedConfig": {
    "url": "https://...",
    "scrapingFrequency": 21600
  }
}
```

### 2. **GOOGLE_SEARCH** ðŸ”
L'URL doit passer par Google Search API.

**Conditions:**
- Source bloquÃ©e (Cloudflare, reCAPTCHA, WAF)
- robots.txt refuse le scraping
- Contenu entiÃ¨rement JavaScript
- Page inaccessible via Cheerio

**Raisons possibles:**
```
- blockageType: CLOUDFLARE
- blockageType: RECAPTCHA
- blockageType: WAF
- isJavaScriptOnly: true
- robotsAllowScraping: false
```

### 3. **API_REQUIRED** ðŸ”‘
L'URL nÃ©cessite une clÃ© API valide.

**Conditions:**
- Content-Type: application/json
- Endpoint d'API dÃ©tectÃ©
- Authentification requise

### 4. **UNSUPPORTED** âŒ
L'URL n'est pas supportÃ©e ou inaccessible.

**Conditions:**
- URL invalide
- Ressource non trouvÃ©e (404)
- Serveur inaccessible
- Contenu vide

---

## ðŸ”§ Installation

```bash
# Installer les dÃ©pendances
npm install axios p-retry

# TypeScript strict mode est activÃ©
npm install --save-dev typescript
```

## ðŸš€ Utilisation

### Utilisation Directe

```typescript
import SourceAnalyzer from './source-analyzer';

const analyzer = new SourceAnalyzer({
  timeout: 10000,
  maxRetries: 2
});

const diagnostic = await analyzer.analyze('https://example.com');

console.log('StratÃ©gie:', diagnostic.strategy);
console.log('Message:', diagnostic.message);
console.log('Recommandations:', diagnostic.recommendations);
console.log('Logs dÃ©taillÃ©s:', diagnostic.logs);
```

### Via le Service

```typescript
import SourceAnalyzerService from './source-analyzer.service';
import { PrismaClient } from '@sentinelle/database';
import logger from './logger';

const prisma = new PrismaClient();
const service = new SourceAnalyzerService(prisma, logger);

const result = await service.analyzeUrl('https://example.com');

// CrÃ©er automatiquement une source si possible
if (!result.requiresUserAction) {
  const source = await service.createSourceFromDiagnostic(
    result.diagnostic,
    brandId,
    organizationId
  );
}
```

### Via API REST

```bash
# Analyser une URL
curl -X POST http://localhost:5001/api/sources/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com",
    "includeDebugLogs": false
  }'

# Analyser et crÃ©er une source
curl -X POST http://localhost:5001/api/sources/analyze-and-create \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com",
    "brandId": "uuid",
    "name": "My Source"
  }'

# Analyser plusieurs URLs
curl -X POST http://localhost:5001/api/sources/analyze/batch \
  -H "Content-Type: application/json" \
  -d '{
    "urls": ["https://url1.com", "https://url2.com"]
  }'
```

---

## ðŸ” DÃ©tections Automatiques

### Blocages DÃ©tectÃ©s

| Blocage | Indicateurs | RÃ©solution |
|---------|------------|-----------|
| **CLOUDFLARE** | En-tÃªtes `cf-ray`, `server: cloudflare` | Google Search API |
| **RECAPTCHA** | `g-recaptcha`, `hcaptcha`, classe recaptcha | Google Search API |
| **WAF** | "Access Denied", "403 Forbidden" | Google Search API |
| **JAVASCRIPT-ONLY** | `__NEXT_DATA__`, `__NUXT__`, `ng-app` | Playwright ou Google Search |

### robots.txt

- âœ… Si permissif: Scraping autorisÃ©
- âŒ Si `Disallow: /`: Google Search API ou affichage erreur
- â“˜ Si absent: Scraping autorisÃ© (par dÃ©faut)

### Logs Disponibles

Chaque Ã©tape est loguÃ©e avec:
- Timestamp
- Niveau (INFO, WARN, ERROR, DEBUG)
- Ã‰tape (INIT, CONNECTION, FETCH, ANALYZE_CONTENT, ROBOTS, STRATEGY, COMPLETE)
- Message explicite
- DÃ©tails optionnels
- DurÃ©e optionnelle

```typescript
diagnostic.logs.forEach(log => {
  console.log(`[${log.timestamp}] ${log.level} - ${log.step}`);
  console.log(`  ${log.message}`);
});
```

---

## ðŸ§ª Tests Unitaires

Le module inclut des tests complets couvrant:

### StratÃ©gies (4 tests de base)
- âœ… SCRAPABLE: HTML valide, contenu accessible
- âœ… GOOGLE_SEARCH: Cloudflare, reCAPTCHA, WAF, JS-only, robots.txt restrictif
- âœ… UNSUPPORTED: URL invalide, 404, page vide, erreur rÃ©seau
- âœ… API_REQUIRED: Endpoints d'API

### Cas Limites
- âœ… Timeouts rÃ©seau
- âœ… GÃ©nÃ©ration de logs dÃ©taillÃ©s
- âœ… Recommandations pertinentes
- âœ… Timestamps valides

### Performance
- âœ… Analyse < 10 secondes

### Messages Utilisateur
- âœ… Clairs et explicites pour chaque stratÃ©gie

```bash
# Lancer les tests
npm run test -- source-analyzer.test.ts

# Avec coverage
npm run test -- --coverage source-analyzer.test.ts
```

---

## ðŸ“Š RÃ©ponse Typique

```json
{
  "success": true,
  "data": {
    "diagnostic": {
      "url": "https://news.example.com",
      "strategy": "SCRAPABLE",
      "status": 200,
      "contentType": "text/html; charset=utf-8",
      "hasContent": true,
      "isJavaScriptOnly": false,
      "blockageType": "NONE",
      "hasRobotsTxt": true,
      "robotsAllowScraping": true,
      "estimatedSize": 45234,
      "message": "Cette source peut Ãªtre scrappÃ©e directement. Les mentions seront collectÃ©es via Cheerio/Playwright.",
      "recommendations": [
        "La source sera scrappÃ©e toutes les 6 heures par dÃ©faut",
        "Vous pouvez ajuster la frÃ©quence de scraping dans les paramÃ¨tres"
      ],
      "logs": [
        {
          "level": "INFO",
          "step": "INIT",
          "message": "Analyse de: https://news.example.com",
          "timestamp": "2026-01-28T10:30:00.000Z"
        },
        {
          "level": "INFO",
          "step": "CONNECTION",
          "message": "Statut: 200 OK",
          "timestamp": "2026-01-28T10:30:00.100Z"
        }
        // ... plus de logs
      ],
      "timestamp": "2026-01-28T10:30:00.500Z"
    },
    "suggestedSourceType": "BLOG",
    "suggestedConfig": {
      "url": "https://news.example.com",
      "scrapingFrequency": 21600,
      "method": "cheerio"
    },
    "requiresUserAction": false,
    "actionDescription": "Vous pouvez crÃ©er une source web pour scraper automatiquement cette URL."
  }
}
```

---

## ðŸ—ï¸ Architecture

### Fichiers

```
api/src/modules/sources/
â”œâ”€â”€ source-analyzer.ts              # Logique principale (400+ lignes)
â”œâ”€â”€ source-analyzer.service.ts       # Service intÃ©gration Prisma
â”œâ”€â”€ source-analyzer.controller.ts    # Endpoints Express
â”œâ”€â”€ source-analyzer.routes.ts        # Routes
â”œâ”€â”€ source-analyzer.test.ts          # Tests unitaires (400+ lignes)
â””â”€â”€ SOURCE_ANALYZER_GUIDE.md        # Documentation complÃ¨te
```

### DÃ©pendances

```typescript
import axios from 'axios';           // RequÃªtes HTTP
import * as cheerio from 'cheerio';  // Parsing HTML
import { Logger } from 'winston';    // Logging
import pRetry from 'p-retry';        // Retries automatiques
```

### Types TypeScript

```typescript
enum CollectionStrategy {
  SCRAPABLE = 'SCRAPABLE',
  API_REQUIRED = 'API_REQUIRED',
  GOOGLE_SEARCH = 'GOOGLE_SEARCH',
  UNSUPPORTED = 'UNSUPPORTED'
}

enum BlockageType {
  CLOUDFLARE = 'CLOUDFLARE',
  RECAPTCHA = 'RECAPTCHA',
  WAF = 'WAF',
  NONE = 'NONE'
}

interface SourceDiagnostic {
  url: string;
  strategy: CollectionStrategy;
  status: number | null;
  hasContent: boolean;
  isJavaScriptOnly: boolean;
  blockageType: BlockageType;
  // ... 10+ autres propriÃ©tÃ©s
  logs: DiagnosticLog[];
  timestamp: Date;
}
```

---

## ðŸ”Œ IntÃ©gration avec Sentinelle

### Workflow Complet

```
1. Utilisateur soumet une URL
   POST /api/sources/analyze-and-create

2. SourceAnalyzer dÃ©tecte la stratÃ©gie
   â†’ SCRAPABLE â†’ CrÃ©e source BLOG/FORUM
   â†’ GOOGLE_SEARCH â†’ CrÃ©e source NEWS
   â†’ UNSUPPORTED â†’ Erreur

3. Source crÃ©Ã©e avec config complÃ¨te
   config: { analysisMeta: {...} }

4. Worker scraping.processor reÃ§oit la source
   â†’ Regarde analysisMeta
   â†’ Utilise Cheerio ou Playwright selon les conditions

5. Collector utilise la meilleure approche
   â†’ Scraping direct OU
   â†’ Google Search API OU
   â†’ API spÃ©cifique

6. Mentions collectÃ©es et stockÃ©es
   â†’ Source.lastScrapedAt = now
   â†’ Mentions â†’ BD
```

### CompatibilitÃ©

âœ… Fonctionnera avec:
- Collectors existants (Web, Twitter, Reddit, etc.)
- Workers existants (scraping.processor, mention.processor)
- Prisma schema (Source model)
- Architecture BullMQ
- Winston logger

---

## âš¡ Performance

| MÃ©trique | Valeur |
|----------|--------|
| **Timeout par dÃ©faut** | 10 secondes |
| **Retries automatiques** | 2 |
| **Temps analyse simple** | 200-500ms |
| **Temps analyse bloquÃ©e** | 300-700ms |
| **Batch (10 URLs)** | 2-5 secondes |
| **Content-length limit** | 5MB |

---

## ðŸ” SÃ©curitÃ© & LÃ©galitÃ©

### RespectÃ©

âœ… robots.txt
- VÃ©rification systÃ©matique
- Refus de scraper si `Disallow: /`

âœ… Pas de contournement
- Pas de proxy
- Pas de contournement Cloudflare
- Pas de scraping de contenu privÃ©

âœ… User-Agent appropriÃ©
- Se prÃ©sente comme un navigateur
- Respecte les bonnes pratiques

### Ã€ ImplÃ©menter CÃ´tÃ© Utilisateur

âš ï¸ Responsable de:
- Avoir les droits lÃ©gaux de scraper
- Respecter les Terms of Service
- GÃ©rer les API keys de maniÃ¨re sÃ©curisÃ©e
- Respecter les rate limits

---

## ðŸ› Debugging

### Activer les logs de debug

```bash
# Avec includeDebugLogs=true
curl -X POST http://localhost:5001/api/sources/analyze \
  -d '{"url": "...", "includeDebugLogs": true}'
```

### Exporter les logs

```typescript
const diagnostic = await analyzer.analyze(url);
const logsJson = service.exportLogsJson(diagnostic);
console.log(logsJson);
```

### Winston Logger

```typescript
const service = new SourceAnalyzerService(
  prisma,
  logger  // Winston logger instance
);

// Les logs seront envoyÃ©s Ã  Winston
// avec le contexte [SourceAnalyzerService]
```

---

## ðŸ“ˆ ExtensibilitÃ©

### Ajouter une Nouvelle DÃ©tection

```typescript
// 1. Ajouter au enum
enum BlockageType {
  CLOUDFLARE = 'CLOUDFLARE',
  // ... autres
  MY_CUSTOM_BLOCKER = 'MY_CUSTOM_BLOCKER'
}

// 2. Ajouter aux indicateurs
private readonly CUSTOM_INDICATORS = ['My Blocker Text'];

// 3. Mettre Ã  jour detectBlockage()
if (html.includes('My Blocker Text')) {
  return BlockageType.MY_CUSTOM_BLOCKER;
}

// 4. Mettre Ã  jour les messages
private generateMessage(...) {
  case MY_CUSTOM_BLOCKER:
    return 'Cette source utilise un blocage custom...';
}
```

### Ajouter une Nouvelle StratÃ©gie

```typescript
// 1. Ajouter Ã  l'enum
enum CollectionStrategy {
  // ... existantes
  RSS_FEED = 'RSS_FEED'
}

// 2. Ajouter la dÃ©tection
if (contentType.includes('application/rss+xml')) {
  return CollectionStrategy.RSS_FEED;
}

// 3. Mettre Ã  jour les messages et recommandations
```

---

## ðŸ“ Changelog

### v1.0.0 (Initial)
- âœ… Analyse automatique d'URLs
- âœ… DÃ©tection de Cloudflare, reCAPTCHA, WAF
- âœ… DÃ©tection JavaScript-only
- âœ… VÃ©rification robots.txt
- âœ… 4 stratÃ©gies principales
- âœ… Logging dÃ©taillÃ©
- âœ… Tests complets
- âœ… API REST + Service

---

## ðŸ¤ Contribution

Pour ajouter une nouvelle fonctionnalitÃ©:

1. CrÃ©er une branche: `git checkout -b feature/xyz`
2. Ajouter des tests: `src/modules/sources/source-analyzer.test.ts`
3. Documenter: Mettre Ã  jour ce README
4. Soumettre une PR

---

## ðŸ“ž Support

Pour les questions ou bugs:

1. VÃ©rifier les logs dÃ©taillÃ©s: `includeDebugLogs=true`
2. Consulter `SOURCE_ANALYZER_GUIDE.md`
3. VÃ©rifier les tests pour des exemples d'utilisation
4. Contacter l'Ã©quipe

---

**Made with â¤ï¸ for Sentinelle Reputation**
