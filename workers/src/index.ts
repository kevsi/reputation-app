import { Worker } from 'bullmq'
import Redis from 'ioredis'
import { scrapingProcessor } from './processors/scraping.processor'
import { mentionProcessor } from './processors/mention.processor'
import { scrapingScheduler } from './scheduler'

const REDIS_URL = process.env.REDIS_URL || 'redis://localhost:6379';

// Parse Redis URL
const url = new URL(REDIS_URL);
// Configuration Redis pour Docker
const redisConfig = {
  host: url.hostname, // Utilise directement le hostname (redis, localhost, etc.)
  port: parseInt(url.port) || 6379,
  password: url.password || undefined,
  enableReadyCheck: false,
  retryDelayOnFailover: 100,
  maxRetriesPerRequest: null  // BullMQ nÃ©cessite null
}

const redisConnection = new Redis(redisConfig)

console.log('ğŸš€ DÃ©marrage des Workers...')
console.log('Redis connection:', { host: url.hostname, port: url.port })

// Worker pour le scraping
const scrapingWorker = new Worker('scraping', scrapingProcessor, {
  connection: redisConnection,
  concurrency: 5,
  limiter: {
    max: 10,
    duration: 60000  // Max 10 jobs par minute
  }
})

// Worker pour le traitement des mentions
const mentionWorker = new Worker('mention', mentionProcessor, {
  connection: redisConnection,
  concurrency: 10
})

// Ã‰vÃ©nements Scraping Worker
scrapingWorker.on('completed', (job) => {
  console.log(`âœ… [SCRAPING] Job ${job.id} terminÃ©`)
})

scrapingWorker.on('failed', (job, err) => {
  console.error(`âŒ [SCRAPING] Job ${job?.id} Ã©chouÃ©:`, err.message)
})

scrapingWorker.on('error', (err) => {
  console.error('âŒ [SCRAPING] Erreur worker:', err)
})

// Ã‰vÃ©nements Mention Worker
mentionWorker.on('completed', (job) => {
  console.log(`âœ… [MENTION] Job ${job.id} terminÃ©`)
})

mentionWorker.on('failed', (job, err) => {
  console.error(`âŒ [MENTION] Job ${job?.id} Ã©chouÃ©:`, err.message)
})

mentionWorker.on('error', (err) => {
  console.error('âŒ [MENTION] Erreur worker:', err)
})

console.log('âœ… Workers dÃ©marrÃ©s')
console.log('ğŸ“¡ Scraping Worker: 5 concurrent jobs')
console.log('ğŸ“ Mention Worker: 10 concurrent jobs')

// DÃ©marrer le scheduler
scrapingScheduler.start().catch((error) => {
  console.error('âŒ Erreur lors du dÃ©marrage du scheduler:', error)
})

// Graceful shutdown
const shutdown = async () => {
  console.log('â³ ArrÃªt gracieux des workers...')

  await scrapingScheduler.stop()
  await scrapingWorker.close()
  await mentionWorker.close()
  await redisConnection.quit()

  console.log('âœ… Workers arrÃªtÃ©s proprement')
  process.exit(0)
}

process.on('SIGTERM', shutdown)
process.on('SIGINT', shutdown)

process.on('uncaughtException', (error) => {
  console.error('âŒ Uncaught Exception:', error)
})

process.on('unhandledRejection', (reason, promise) => {
  console.error('âŒ Unhandled Rejection at:', promise, 'reason:', reason)
})