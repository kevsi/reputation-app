# ğŸ—ï¸ ANALYSE ARCHITECTURALE COMPLÃˆTE - SENTINELLE REPUTATION

**Date:** 7 FÃ©vrier 2026  
**Analyste:** Architecte Logiciel Senior  
**Objectif:** Audit complet de l'architecture API, sÃ©curitÃ©, ingestion de donnÃ©es et scalabilitÃ©

---

## ğŸ“‹ TABLE DES MATIÃˆRES

1. [Analyse Globale de l'Architecture](#1-analyse-globale)
2. [Authentification & SÃ©curitÃ©](#2-authentification--sÃ©curitÃ©)
3. [Ingestion des DonnÃ©es (Scraping)](#3-ingestion-des-donnÃ©es)
4. [Pagination & VolumÃ©trie](#4-pagination--volumÃ©trie)
5. [Architecture IdÃ©ale ProposÃ©e](#5-architecture-idÃ©ale)
6. [AmÃ©liorations & Alternatives](#6-amÃ©liorations--alternatives)
7. [Risques Futurs & Solutions](#7-risques-futurs)

---

## 1ï¸âƒ£ ANALYSE GLOBALE DE L'ARCHITECTURE

### 1.1 Structure Actuelle du Projet

```
sentinelle-reputation/
â”œâ”€â”€ api/                    # API Backend (Node.js + Express + Prisma)
â”œâ”€â”€ scrapers/               # Scrapers Python (Scrapy)
â”œâ”€â”€ ai-service/             # Service IA (Python + FastAPI)
â”œâ”€â”€ database/               # SchÃ©ma Prisma + Migrations
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/               # Frontend principal (React + Vite)
â”‚   â”œâ”€â”€ admin/             # Panel admin
â”‚   â””â”€â”€ landing/           # Site marketing
â”œâ”€â”€ shared/                # Types et constantes partagÃ©s
â””â”€â”€ infrastructure/        # Docker + K8s configs
```

### 1.2 Architecture Actuelle (3 Services)

**âœ… BONNE APPROCHE : Modular Monolith**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ARCHITECTURE ACTUELLE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚â”€â”€â”€â”€â”€â–¶â”‚  API (Node)  â”‚â”€â”€â”€â”€â”€â–¶â”‚  PostgreSQL  â”‚
â”‚  React/Vite  â”‚      â”‚   Express    â”‚      â”‚   Database   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Scrapers   â”‚  â”‚  AI Service   â”‚
            â”‚   (Python)   â”‚  â”‚   (Python)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Redis     â”‚
            â”‚  (Queue/Cache)â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Modules API IdentifiÃ©s (14 modules)

| Module | ResponsabilitÃ© | Ã‰tat | Authentification |
|--------|---------------|------|------------------|
| **auth** | Inscription, login, tokens JWT | âœ… Complet | Public + Protected |
| **users** | Gestion utilisateurs | âœ… Complet | âœ… requireAuth |
| **organizations** | Gestion organisations | âœ… Complet | âœ… requireAuth |
| **billing** | Abonnements Stripe | âœ… Complet | âœ… requireAuth |
| **brands** | Marques surveillÃ©es | âœ… Complet | âœ… requireAuth |
| **sources** | Sources de donnÃ©es | âœ… Complet | âœ… requireAuth |
| **mentions** | Mentions collectÃ©es | âœ… Complet | âœ… requireAuth |
| **keywords** | Mots-clÃ©s surveillÃ©s | âœ… Complet | âœ… requireAuth |
| **alerts** | Alertes conditionnelles | âœ… Complet | âœ… requireAuth |
| **actions** | Actions stratÃ©giques | âœ… Complet | âœ… requireAuth |
| **analytics** | Analyses et mÃ©triques | âœ… Complet | âœ… requireAuth |
| **reports** | GÃ©nÃ©ration de rapports | âœ… Complet | âœ… requireAuth |
| **notifications** | Notifications utilisateur | âœ… Complet | âœ… requireAuth |
| **system** | Status systÃ¨me/AI | âœ… Complet | âœ… requireAuth |

### 1.4 Flux de DonnÃ©es par Module

#### ğŸ“Š Module MENTIONS (Exemple Type)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUX MENTIONS                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. RÃ‰CEPTION
   Scraper Python â†’ PostgreSQL (via pipeline.py)
   â†“
2. VALIDATION
   Schema Prisma (externalId unique, platform enum)
   â†“
3. STOCKAGE
   Table mentions (brandId, sourceId, content, sentiment)
   â†“
4. EXPOSITION
   GET /api/v1/mentions?brandId=X
   â”œâ”€ requireAuth middleware
   â”œâ”€ mentions.controller.ts
   â”œâ”€ mentions.service.ts
   â””â”€ mentions.repository.ts
```

#### ğŸ”Œ Module SOURCES

```
1. RÃ‰CEPTION (Frontend)
   POST /api/v1/sources
   Body: { brandId, type, name, config }
   â†“
2. VALIDATION
   â”œâ”€ VÃ©rification plan limits (maxSources)
   â”œâ”€ Validation credentials (testConnection)
   â””â”€ VÃ©rification domaines interdits
   â†“
3. STOCKAGE
   Table sources (brandId, type, config, isActive)
   â†“
4. DÃ‰CLENCHEMENT SCRAPING
   scrapingQueue.add('scrape-source', { sourceId })
   â†“
5. EXPOSITION
   GET /api/v1/sources?organizationId=X
```

---

## 2ï¸âƒ£ AUTHENTIFICATION & SÃ‰CURITÃ‰

### 2.1 MÃ©canisme d'Authentification Actuel

**âœ… ARCHITECTURE CENTRALISÃ‰E ET COHÃ‰RENTE**

```typescript
// Flux d'authentification
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AUTHENTIFICATION JWT                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. LOGIN
   POST /api/v1/auth/login
   â”œâ”€ Validation email/password (Zod)
   â”œâ”€ VÃ©rification bcrypt
   â”œâ”€ GÃ©nÃ©ration JWT (accessToken + refreshToken)
   â””â”€ Retour tokens + user data

2. PROTECTION DES ROUTES
   Middleware: requireAuth
   â”œâ”€ Extraction Bearer token
   â”œâ”€ VÃ©rification JWT signature
   â”œâ”€ RÃ©cupÃ©ration user depuis DB
   â””â”€ Injection req.user

3. REFRESH TOKEN
   POST /api/v1/auth/refresh
   â”œâ”€ Validation refreshToken
   â”œâ”€ GÃ©nÃ©ration nouveau accessToken
   â””â”€ Retour nouveau token
```

### 2.2 Middleware de SÃ©curitÃ© (auth.middleware.ts)

```typescript
export const requireAuth = async (req, res, next) => {
  // 1. Extraction du token
  const authHeader = req.headers.authorization;
  if (!authHeader?.startsWith('Bearer ')) {
    throw new AppError('No token provided', 401, 'NO_TOKEN');
  }

  // 2. VÃ©rification JWT
  const token = authHeader.substring(7);
  const payload = jwtService.verifyToken(token);

  // 3. RÃ©cupÃ©ration user Ã  jour depuis DB
  const user = await prisma.user.findUnique({
    where: { id: payload.userId },
    include: { organization: true }
  });

  if (!user) {
    throw new AppError('User not found', 401, 'USER_NOT_FOUND');
  }

  // 4. Injection dans req.user
  req.user = {
    userId: user.id,
    email: user.email,
    organizationId: user.organizationId,
    role: user.role
  };

  next();
};
```

### 2.3 Analyse de CohÃ©rence entre Modules

**âœ… TOUS LES MODULES UTILISENT LE MÃŠME MÃ‰CANISME**

| Module | Middleware Auth | VÃ©rification Org | VÃ©rification Plan |
|--------|----------------|------------------|-------------------|
| mentions | âœ… requireAuth | âœ… Via brandId | âŒ Non |
| sources | âœ… requireAuth | âœ… Via brandId | âœ… Oui (maxSources) |
| brands | âœ… requireAuth | âœ… Direct | âœ… Oui (maxBrands) |
| alerts | âœ… requireAuth | âœ… Via brandId | âŒ Non |
| keywords | âœ… requireAuth | âœ… Via brandId | âŒ Non |
| actions | âœ… requireAuth | âŒ Non | âŒ Non |
| analytics | âœ… requireAuth | âœ… Via brandId | âŒ Non |
| reports | âœ… requireAuth | âœ… Via brandId | âŒ Non |

### 2.4 Failles de SÃ©curitÃ© IdentifiÃ©es

#### ğŸ”´ CRITIQUE : Isolation des DonnÃ©es

**ProblÃ¨me:** Certains modules ne vÃ©rifient pas l'ownership

```typescript
// âŒ FAILLE : Module Actions
async getAllActions(req: Request, res: Response) {
  // RÃ©cupÃ¨re TOUTES les actions sans filtrer par organization
  const actions = await prisma.action.findMany();
  // âš ï¸ Un utilisateur peut voir les actions d'autres orgs
}

// âœ… CORRECT : Module Mentions
async getMentions(req: Request, res: Response) {
  const user = req.user;
  const mentions = await prisma.mention.findMany({
    where: {
      brand: {
        organizationId: user.organizationId // âœ… Filtrage
      }
    }
  });
}
```

#### ğŸŸ  MOYEN : Rate Limiting Global

**ProblÃ¨me:** Rate limiting appliquÃ© globalement, pas par utilisateur

```typescript
// Actuel (app.ts)
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100 // Limite globale
});

// âš ï¸ Un utilisateur peut consommer toute la limite
```

#### ğŸŸ¡ FAIBLE : Validation des Inputs

**ProblÃ¨me:** Validation Zod incohÃ©rente

```typescript
// âœ… BIEN : Module Auth
router.post('/login', validate(loginSchema), authController.login);

// âŒ MAL : Module Sources
router.post('/', sourcesController.createSource); // Pas de validation Zod
```

### 2.5 Recommandations SÃ©curitÃ©

```typescript
// 1. Middleware d'isolation des donnÃ©es
export const requireOrganization = async (req, res, next) => {
  const { organizationId } = req.user;
  
  // VÃ©rifier que la ressource appartient Ã  l'org
  const resource = await prisma[req.resourceType].findFirst({
    where: {
      id: req.params.id,
      organizationId
    }
  });
  
  if (!resource) {
    throw new AppError('Resource not found', 404, 'NOT_FOUND');
  }
  
  next();
};

// 2. Rate limiting par utilisateur
const userLimiter = rateLimit({
  keyGenerator: (req) => req.user?.userId || req.ip,
  windowMs: 15 * 60 * 1000,
  max: 100
});

// 3. Validation Zod systÃ©matique
router.post('/', 
  requireAuth,
  validate(createSourceSchema),
  sourcesController.createSource
);
```

---

## 3ï¸âƒ£ INGESTION DES DONNÃ‰ES (SCRAPING)

### 3.1 Architecture de Scraping Actuelle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FLUX D'INGESTION DES DONNÃ‰ES                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. CONFIGURATION SOURCE
   Frontend â†’ POST /api/v1/sources
   â”œâ”€ Validation credentials
   â”œâ”€ CrÃ©ation source en DB
   â””â”€ DÃ©clenchement premier scraping

2. QUEUE SCRAPING
   scrapingQueue.add('scrape-source', { sourceId })
   â”œâ”€ Redis (BullMQ)
   â””â”€ Job persistÃ©

3. WORKER PYTHON (Scrapy)
   â”œâ”€ RÃ©cupÃ©ration job depuis Redis
   â”œâ”€ Lecture config source depuis DB
   â”œâ”€ ExÃ©cution spider (trustpilot.py, news.py, etc.)
   â””â”€ Collecte mentions

4. PIPELINE PYTHON
   â”œâ”€ Validation item (items.py)
   â”œâ”€ Enrichissement metadata
   â””â”€ Insertion PostgreSQL (pipelines.py)

5. ANALYSE IA (Optionnel)
   â”œâ”€ DÃ©tection sentiment
   â”œâ”€ Extraction keywords
   â””â”€ Update mention.sentiment
```

### 3.2 Scrapers Disponibles

| Scraper | Fichier | Ã‰tat | Pagination | Format Output |
|---------|---------|------|------------|---------------|
| Trustpilot | trustpilot.py | âœ… Actif | âœ… Oui (next page) | JSONL + DB |
| Google Reviews | google_reviews.py | âœ… Actif | âŒ Non | JSONL + DB |
| News | news.py | âœ… Actif | âŒ Non | JSONL + DB |
| SensCritique | senscritique.py | âœ… Actif | âŒ Non | JSONL + DB |

### 3.3 Pipeline d'Insertion (pipelines.py)

```python
class DatabasePipeline:
    def process_item(self, item, spider):
        # 1. RÃ©cupÃ©rer brandId depuis source
        self.cur.execute("SELECT \"brandId\" FROM sources WHERE id = %s", 
                        (source_id,))
        brand_id = self.cur.fetchone()[0]
        
        # 2. InsÃ©rer mention avec UPSERT
        query = """
            INSERT INTO mentions (
                id, "brandId", "sourceId", platform, author, content,
                url, "publishedAt", "scrapedAt", sentiment, "externalId"
            ) VALUES (
                DEFAULT, %s, %s, %s, %s, %s, %s, %s, %s, 'NEUTRAL', %s
            )
            ON CONFLICT ("externalId", platform) DO UPDATE SET
                content = EXCLUDED.content,
                "publishedAt" = EXCLUDED."publishedAt";
        """
        
        self.cur.execute(query, (
            brand_id, source_id, item['platform'],
            item['author'], item['content'], item['url'],
            item['published_at'], item['scraped_at'], item['external_id']
        ))
        self.conn.commit()
```

### 3.4 ProblÃ¨mes IdentifiÃ©s

#### ğŸ”´ CRITIQUE : Pas de Workers Node.js

**ProblÃ¨me:** Le dossier `workers/` n'existe pas dans l'API

```bash
# Attendu (selon README.md)
api/
â””â”€â”€ workers/
    â”œâ”€â”€ processors/
    â”‚   â”œâ”€â”€ scraping.processor.ts
    â”‚   â””â”€â”€ analysis.processor.ts
    â””â”€â”€ jobs/
        â””â”€â”€ scheduled-scraping.job.ts

# RÃ©el
âŒ Dossier workers/ absent
```

**Impact:**
- Pas de scheduler automatique
- Pas de gestion des jobs rÃ©currents
- Scraping manuel uniquement

#### ğŸ”´ CRITIQUE : Pas de Gestion d'Erreurs Scraping

```python
# pipelines.py
try:
    self.cur.execute(query, ...)
    self.conn.commit()
except Exception as e:
    self.logger.error(f"âŒ Failed to save item: {e}")
    self.conn.rollback()
    # âš ï¸ Item perdu, pas de retry
```

#### ğŸŸ  MOYEN : Pas de Validation de Format

```python
# Pas de validation Pydantic/Marshmallow
item['content']  # Peut Ãªtre None, vide, ou trop long
item['published_at']  # Format non vÃ©rifiÃ©
```

### 3.5 Recommandations Ingestion

```typescript
// 1. CrÃ©er workers/ avec BullMQ
// api/src/workers/scraping.processor.ts
import { Worker } from 'bullmq';
import { exec } from 'child_process';

const worker = new Worker('scraping', async (job) => {
  const { sourceId } = job.data;
  
  // RÃ©cupÃ©rer config source
  const source = await prisma.source.findUnique({
    where: { id: sourceId },
    include: { brand: true }
  });
  
  // Lancer scraper Python
  const command = `scrapy crawl ${source.type.toLowerCase()} \
    -a source_id=${sourceId} \
    -a company_name=${source.config.companyName}`;
  
  return new Promise((resolve, reject) => {
    exec(command, (error, stdout, stderr) => {
      if (error) reject(error);
      else resolve({ stdout, stderr });
    });
  });
}, {
  connection: redisConnection,
  concurrency: 5
});

// 2. Scheduler rÃ©current
import cron from 'node-cron';

cron.schedule('*/30 * * * *', async () => {
  const sources = await prisma.source.findMany({
    where: { isActive: true }
  });
  
  for (const source of sources) {
    const lastScraped = source.lastScrapedAt;
    const frequency = source.scrapingFrequency; // en secondes
    
    if (!lastScraped || Date.now() - lastScraped.getTime() > frequency * 1000) {
      await scrapingQueue.add('scrape-source', { sourceId: source.id });
    }
  }
});
```

---

## 4ï¸âƒ£ PAGINATION & VOLUMÃ‰TRIE

### 4.1 Pagination Actuelle

#### API (mentions.service.ts)

```typescript
// âŒ PAS DE PAGINATION IMPLÃ‰MENTÃ‰E
async getMentions(filters) {
  return await prisma.mention.findMany({
    where: filters,
    include: { brand: true, source: true },
    orderBy: { createdAt: 'desc' }
    // âš ï¸ Pas de take/skip
  });
}
```

#### Scrapers (trustpilot.py)

```python
# âœ… PAGINATION IMPLÃ‰MENTÃ‰E
def parse(self, response):
    # Traiter les reviews
    for review in reviews:
        yield item
    
    # Pagination
    next_page = response.css('a[name="pagination-button-next"]::attr(href)').get()
    if next_page:
        yield response.follow(next_page, callback=self.parse)
```

### 4.2 ProblÃ¨mes de VolumÃ©trie

#### ğŸ”´ CRITIQUE : Pas de Limite sur les RequÃªtes

```typescript
// âŒ DANGEREUX : Peut retourner 1M+ mentions
GET /api/v1/mentions?brandId=X
// Pas de pagination â†’ Timeout, OOM

// âŒ DANGEREUX : Pas de limite sur le scraping
// Un scraper peut tourner indÃ©finiment
```

#### ğŸ”´ CRITIQUE : Pas de Batch Processing

```python
# pipelines.py
for item in items:
    self.cur.execute(query, ...)  # 1 query par item
    self.conn.commit()  # 1 commit par item
    
# âš ï¸ 10,000 items = 10,000 queries + commits
```

### 4.3 Solution de Pagination Robuste

```typescript
// shared/utils/pagination.ts
export interface PaginationParams {
  page?: number;
  limit?: number;
  sortBy?: string;
  sortOrder?: 'asc' | 'desc';
}

export interface PaginatedResponse<T> {
  data: T[];
  pagination: {
    page: number;
    limit: number;
    total: number;
    totalPages: number;
    hasNext: boolean;
    hasPrev: boolean;
  };
}

export async function paginate<T>(
  model: any,
  where: any,
  params: PaginationParams
): Promise<PaginatedResponse<T>> {
  const page = Math.max(1, params.page || 1);
  const limit = Math.min(100, Math.max(1, params.limit || 20));
  const skip = (page - 1) * limit;
  
  const [data, total] = await Promise.all([
    model.findMany({
      where,
      skip,
      take: limit,
      orderBy: { [params.sortBy || 'createdAt']: params.sortOrder || 'desc' }
    }),
    model.count({ where })
  ]);
  
  return {
    data,
    pagination: {
      page,
      limit,
      total,
      totalPages: Math.ceil(total / limit),
      hasNext: page * limit < total,
      hasPrev: page > 1
    }
  };
}

// Utilisation
async getMentions(filters, pagination: PaginationParams) {
  return await paginate(prisma.mention, filters, pagination);
}
```

```python
# scrapers/pipelines.py - Batch Insert
class DatabasePipeline:
    def __init__(self):
        self.items_buffer = []
        self.buffer_size = 100
    
    def process_item(self, item, spider):
        self.items_buffer.append(item)
        
        if len(self.items_buffer) >= self.buffer_size:
            self.flush_buffer()
        
        return item
    
    def flush_buffer(self):
        if not self.items_buffer:
            return
        
        # Batch insert avec executemany
        query = """INSERT INTO mentions (...) VALUES (%s, %s, ...)"""
        values = [(item['brand_id'], item['content'], ...) 
                  for item in self.items_buffer]
        
        self.cur.executemany(query, values)
        self.conn.commit()
        
        self.items_buffer = []
    
    def close_spider(self, spider):
        self.flush_buffer()  # Flush remaining items
```

---

## 5ï¸âƒ£ ARCHITECTURE IDÃ‰ALE PROPOSÃ‰E

### 5.1 Flux de DonnÃ©es OptimisÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ARCHITECTURE CIBLE (PRODUCTION-READY)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚
â”‚  (React)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTPS + JWT
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API GATEWAY                            â”‚
â”‚  - Rate Limiting (par user)                              â”‚
â”‚  - Authentication (JWT)                                  â”‚
â”‚  - Request Validation (Zod)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API MONOLITH (Express)                   â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Auth      â”‚  â”‚  Mentions   â”‚  â”‚  Analytics  â”‚     â”‚
â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Sources    â”‚  â”‚   Brands    â”‚  â”‚   Reports   â”‚     â”‚
â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
       â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚        â”‚    Redis     â”‚
â”‚  (Primary)   â”‚        â”‚ (Cache/Queue)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Workers    â”‚
                        â”‚  (BullMQ)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Scrapers    â”‚     â”‚ AI Service   â”‚
            â”‚   (Python)    â”‚     â”‚  (Python)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Structure des Endpoints IdÃ©ale

```
/api/v1/
â”œâ”€â”€ /auth
â”‚   â”œâ”€â”€ POST   /register
â”‚   â”œâ”€â”€ POST   /login
â”‚   â”œâ”€â”€ POST   /logout
â”‚   â”œâ”€â”€ POST   /refresh
â”‚   â”œâ”€â”€ POST   /forgot-password
â”‚   â”œâ”€â”€ POST   /reset-password
â”‚   â””â”€â”€ GET    /me
â”‚
â”œâ”€â”€ /organizations
â”‚   â”œâ”€â”€ GET    /
â”‚   â”œâ”€â”€ POST   /
â”‚   â”œâ”€â”€ GET    /:id
â”‚   â”œâ”€â”€ PATCH  /:id
â”‚   â””â”€â”€ DELETE /:id
â”‚
â”œâ”€â”€ /brands
â”‚   â”œâ”€â”€ GET    /?organizationId=X&page=1&limit=20
â”‚   â”œâ”€â”€ POST   /
â”‚   â”œâ”€â”€ GET    /:id
â”‚   â”œâ”€â”€ PATCH  /:id
â”‚   â””â”€â”€ DELETE /:id
â”‚
â”œâ”€â”€ /sources
â”‚   â”œâ”€â”€ GET    /?brandId=X&page=1&limit=20
â”‚   â”œâ”€â”€ POST   /
â”‚   â”œâ”€â”€ GET    /:id
â”‚   â”œâ”€â”€ PATCH  /:id
â”‚   â”œâ”€â”€ DELETE /:id
â”‚   â”œâ”€â”€ POST   /test-connection
â”‚   â””â”€â”€ POST   /:id/scrape-now
â”‚
â”œâ”€â”€ /mentions
â”‚   â”œâ”€â”€ GET    /?brandId=X&sentiment=NEGATIVE&page=1&limit=50
â”‚   â”œâ”€â”€ POST   /search (filtres avancÃ©s)
â”‚   â”œâ”€â”€ GET    /:id
â”‚   â”œâ”€â”€ PATCH  /:id
â”‚   â”œâ”€â”€ DELETE /:id
â”‚   â””â”€â”€ POST   /batch-action
â”‚
â”œâ”€â”€ /analytics
â”‚   â”œâ”€â”€ GET    /summary?brandId=X&period=30d
â”‚   â”œâ”€â”€ GET    /sentiment-breakdown?brandId=X
â”‚   â”œâ”€â”€ GET    /time-series?brandId=X&period=daily
â”‚   â””â”€â”€ GET    /top-keywords?brandId=X&limit=10
â”‚
â”œâ”€â”€ /alerts
â”‚   â”œâ”€â”€ GET    /?brandId=X&status=NEW
â”‚   â”œâ”€â”€ POST   /
â”‚   â”œâ”€â”€ GET    /:id
â”‚   â”œâ”€â”€ PATCH  /:id
â”‚   â””â”€â”€ DELETE /:id
â”‚
â”œâ”€â”€ /reports
â”‚   â”œâ”€â”€ GET    /?brandId=X
â”‚   â”œâ”€â”€ POST   /generate
â”‚   â”œâ”€â”€ GET    /:id
â”‚   â””â”€â”€ GET    /:id/download
â”‚
â””â”€â”€ /system
    â”œâ”€â”€ GET    /health
    â”œâ”€â”€ GET    /status
    â””â”€â”€ GET    /metrics
```

### 5.3 Structure de Dossiers OptimisÃ©e

```
api/src/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ database.ts
â”‚   â”œâ”€â”€ redis.ts
â”‚   â”œâ”€â”€ queue.ts
â”‚   â””â”€â”€ app.ts
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ auth.routes.ts
â”‚   â”‚   â”œâ”€â”€ auth.controller.ts
â”‚   â”‚   â”œâ”€â”€ auth.service.ts
â”‚   â”‚   â”œâ”€â”€ jwt.service.ts
â”‚   â”‚   â”œâ”€â”€ password.service.ts
â”‚   â”‚   â””â”€â”€ auth.validation.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ mentions/
â”‚   â”‚   â”œâ”€â”€ mentions.routes.ts
â”‚   â”‚   â”œâ”€â”€ mentions.controller.ts
â”‚   â”‚   â”œâ”€â”€ mentions.service.ts
â”‚   â”‚   â”œâ”€â”€ mentions.repository.ts
â”‚   â”‚   â”œâ”€â”€ mentions.validation.ts
â”‚   â”‚   â””â”€â”€ mentions.types.ts
â”‚   â”‚
â”‚   â””â”€â”€ [autres modules...]
â”‚
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ auth.middleware.ts
â”‚   â”‚   â”œâ”€â”€ validate.middleware.ts
â”‚   â”‚   â”œâ”€â”€ rate-limit.middleware.ts
â”‚   â”‚   â”œâ”€â”€ plan-guard.middleware.ts
â”‚   â”‚   â””â”€â”€ error.middleware.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ pagination.ts
â”‚   â”‚   â”œâ”€â”€ api-response.ts
â”‚   â”‚   â”œâ”€â”€ errors.ts
â”‚   â”‚   â””â”€â”€ validators.ts
â”‚   â”‚
â”‚   â””â”€â”€ database/
â”‚       â”œâ”€â”€ prisma.client.ts
â”‚       â””â”€â”€ base.repository.ts
â”‚
â”œâ”€â”€ workers/
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ scraping.processor.ts
â”‚   â”‚   â”œâ”€â”€ analysis.processor.ts
â”‚   â”‚   â””â”€â”€ notifications.processor.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ scheduled-scraping.job.ts
â”‚   â”‚   â”œâ”€â”€ daily-analytics.job.ts
â”‚   â”‚   â””â”€â”€ cleanup.job.ts
â”‚   â”‚
â”‚   â””â”€â”€ index.ts
â”‚
â””â”€â”€ infrastructure/
    â”œâ”€â”€ queue/
    â”‚   â”œâ”€â”€ scraping.queue.ts
    â”‚   â””â”€â”€ queue.service.ts
    â”‚
    â”œâ”€â”€ cache/
    â”‚   â””â”€â”€ redis.service.ts
    â”‚
    â””â”€â”€ logger/
        â””â”€â”€ logger.service.ts
```

---

## 6ï¸âƒ£ AMÃ‰LIORATIONS & ALTERNATIVES

### 6.1 AmÃ©lioration 1 : Validation CentralisÃ©e

**ProblÃ¨me Actuel:** Validation incohÃ©rente

```typescript
// âŒ Actuel : Validation manuelle
if (!brandId || !type || !name) {
  res.status(400).json({ error: 'Missing fields' });
}

// âœ… ProposÃ© : Validation Zod centralisÃ©e
// shared/validators/schemas.ts
export const createSourceSchema = z.object({
  brandId: z.string().cuid(),
  type: z.enum(['TRUSTPILOT', 'GOOGLE_REVIEWS', 'NEWS']),
  name: z.string().min(3).max(100),
  config: z.object({
    companyName: z.string().optional(),
    url: z.string().url().optional()
  })
});

// Utilisation
router.post('/', 
  requireAuth,
  validate(createSourceSchema),
  sourcesController.createSource
);
```

### 6.2 AmÃ©lioration 2 : Repository Pattern

**ProblÃ¨me Actuel:** Logique DB dans les services

```typescript
// âŒ Actuel : Service fait tout
class SourcesService {
  async createSource(input) {
    const brand = await prisma.brand.findUnique(...);
    const count = await prisma.source.count(...);
    const source = await prisma.source.create(...);
    return source;
  }
}

// âœ… ProposÃ© : SÃ©paration Repository
// sources.repository.ts
class SourcesRepository {
  async findById(id: string) {
    return prisma.source.findUnique({ where: { id } });
  }
  
  async findByBrand(brandId: string) {
    return prisma.source.findMany({ where: { brandId } });
  }
  
  async create(data: CreateSourceDTO) {
    return prisma.source.create({ data });
  }
  
  async countByOrganization(orgId: string) {
    return prisma.source.count({
      where: { brand: { organizationId: orgId } }
    });
  }
}

// sources.service.ts
class SourcesService {
  constructor(
    private repo: SourcesRepository,
    private brandRepo: BrandsRepository
  ) {}
  
  async createSource(input) {
    const brand = await this.brandRepo.findById(input.brandId);
    const count = await this.repo.countByOrganization(brand.organizationId);
    
    if (count >= maxSources) {
      throw new AppError('Limit reached', 403);
    }
    
    return await this.repo.create(input);
  }
}
```

### 6.3 AmÃ©lioration 3 : Event-Driven Architecture

**ProblÃ¨me Actuel:** Couplage fort

```typescript
// âŒ Actuel : Tout dans le controller
async createSource(req, res) {
  const source = await sourcesService.createSource(input);
  await scrapingQueue.add('scrape', { sourceId: source.id });
  await notificationService.notify('Source created');
  await analyticsService.track('source_created');
  res.json(source);
}

// âœ… ProposÃ© : Event Emitter
// infrastructure/events/event-bus.ts
import { EventEmitter } from 'events';

export const eventBus = new EventEmitter();

// sources.service.ts
async createSource(input) {
  const source = await this.repo.create(input);
  
  // Ã‰mettre Ã©vÃ©nement
  eventBus.emit('source.created', { source });
  
  return source;
}

// listeners/source.listeners.ts
eventBus.on('source.created', async ({ source }) => {
  await scrapingQueue.add('scrape', { sourceId: source.id });
  await notificationService.notify('Source created');
  await analyticsService.track('source_created');
});
```

### 6.4 Alternative : GraphQL au lieu de REST

**Avantages:**
- RequÃªtes flexibles (Ã©vite over-fetching)
- Typage fort automatique
- Subscriptions temps rÃ©el

```graphql
# Exemple de requÃªte GraphQL
query GetMentions($brandId: ID!, $page: Int!, $limit: Int!) {
  mentions(brandId: $brandId, page: $page, limit: $limit) {
    data {
      id
      content
      sentiment
      author
      source {
        name
        type
      }
    }
    pagination {
      total
      hasNext
    }
  }
}
```

**InconvÃ©nients:**
- Courbe d'apprentissage
- ComplexitÃ© accrue
- Caching plus difficile

**Recommandation:** âŒ Garder REST pour l'instant (simplicitÃ©)

---

## 7ï¸âƒ£ RISQUES FUTURS & SOLUTIONS

### 7.1 Risque 1 : ScalabilitÃ© Base de DonnÃ©es

**ProblÃ¨me:** PostgreSQL unique point de dÃ©faillance

**SymptÃ´mes futurs:**
- RequÃªtes lentes (>1s) avec 1M+ mentions
- Locks sur les tables
- Backup/restore longs

**Solutions:**

```sql
-- 1. Indexes optimisÃ©s
CREATE INDEX CONCURRENTLY idx_mentions_brand_sentiment 
ON mentions(brandId, sentiment, publishedAt DESC);

CREATE INDEX CONCURRENTLY idx_mentions_search 
ON mentions USING gin(to_tsvector('french', content));

-- 2. Partitioning par date
CREATE TABLE mentions_2026_01 PARTITION OF mentions
FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- 3. Read Replicas
-- Master: Writes
-- Replica 1: Analytics queries
-- Replica 2: Mentions listing
```

```typescript
// Prisma avec Read Replicas
const prismaWrite = new PrismaClient({
  datasources: { db: { url: process.env.DATABASE_URL } }
});

const prismaRead = new PrismaClient({
  datasources: { db: { url: process.env.DATABASE_READ_URL } }
});

// Utilisation
async getMentions() {
  return prismaRead.mention.findMany(); // Read replica
}

async createMention() {
  return prismaWrite.mention.create(); // Master
}
```

### 7.2 Risque 2 : DÃ©passement Limites de Scraping

**ProblÃ¨me:** Scrapers bloquÃ©s par les sites cibles

**SymptÃ´mes futurs:**
- IP bannie (Trustpilot, Google)
- Rate limiting (429 errors)
- CAPTCHAs

**Solutions:**

```python
# 1. Rotation de proxies
# scrapers/settings.py
ROTATING_PROXY_LIST = [
    'proxy1.example.com:8000',
    'proxy2.example.com:8000',
]

# 2. User-Agent rotation
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)...',
]

# 3. Delays adaptatifs
AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 5
AUTOTHROTTLE_MAX_DELAY = 60

# 4. Retry avec backoff exponentiel
RETRY_TIMES = 3
RETRY_HTTP_CODES = [500, 502, 503, 504, 408, 429]
```

```typescript
// API: Circuit Breaker pattern
class ScraperCircuitBreaker {
  private failures = 0;
  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  
  async execute(sourceId: string) {
    if (this.state === 'OPEN') {
      throw new Error('Circuit breaker OPEN');
    }
    
    try {
      await scrapingQueue.add('scrape', { sourceId });
      this.failures = 0;
      this.state = 'CLOSED';
    } catch (error) {
      this.failures++;
      
      if (this.failures >= 5) {
        this.state = 'OPEN';
        setTimeout(() => this.state = 'HALF_OPEN', 60000);
      }
      
      throw error;
    }
  }
}
```

### 7.3 Risque 3 : CoÃ»ts d'Infrastructure

**ProblÃ¨me:** CoÃ»ts explosifs avec la croissance

**Projection:**

| Utilisateurs | Mentions/jour | DB Size | CoÃ»t/mois |
|--------------|---------------|---------|-----------|
| 100 | 10,000 | 5 GB | $50 |
| 1,000 | 100,000 | 50 GB | $200 |
| 10,000 | 1,000,000 | 500 GB | $1,000 |
| 100,000 | 10,000,000 | 5 TB | $5,000+ |

**Solutions:**

```typescript
// 1. Archivage automatique
cron.schedule('0 0 * * *', async () => {
  const sixMonthsAgo = new Date();
  sixMonthsAgo.setMonth(sixMonthsAgo.getMonth() - 6);
  
  // Archiver mentions anciennes vers S3
  const oldMentions = await prisma.mention.findMany({
    where: { createdAt: { lt: sixMonthsAgo } }
  });
  
  await s3.upload({
    Bucket: 'sentinelle-archive',
    Key: `mentions-${Date.now()}.json.gz`,
    Body: gzip(JSON.stringify(oldMentions))
  });
  
  // Supprimer de la DB
  await prisma.mention.deleteMany({
    where: { createdAt: { lt: sixMonthsAgo } }
  });
});

// 2. Compression des donnÃ©es
// Stocker seulement les mÃ©tadonnÃ©es, pas le contenu complet
interface MentionCompact {
  id: string;
  brandId: string;
  sentiment: string;
  publishedAt: Date;
  contentHash: string; // SHA256 du contenu
  s3Key?: string; // Lien vers contenu complet si nÃ©cessaire
}

// 3. Limites par plan
const PLAN_LIMITS = {
  FREE: {
    maxMentionsStored: 1000,
    retentionDays: 30
  },
  PRO: {
    maxMentionsStored: 50000,
    retentionDays: 180
  },
  ENTERPRISE: {
    maxMentionsStored: -1, // IllimitÃ©
    retentionDays: 365
  }
};
```

### 7.4 Risque 4 : SÃ©curitÃ© des DonnÃ©es

**ProblÃ¨me:** Fuite de donnÃ©es sensibles

**Vecteurs d'attaque:**
- SQL Injection
- XSS dans les mentions
- AccÃ¨s non autorisÃ© aux donnÃ©es

**Solutions:**

```typescript
// 1. Sanitization des inputs
import DOMPurify from 'isomorphic-dompurify';

async createMention(data) {
  const sanitized = {
    ...data,
    content: DOMPurify.sanitize(data.content),
    author: DOMPurify.sanitize(data.author)
  };
  
  return prisma.mention.create({ data: sanitized });
}

// 2. Encryption at rest
// database/prisma/schema.prisma
model Source {
  id String @id
  config Json @db.JsonB // âš ï¸ Credentials en clair
}

// Chiffrement AES-256
import crypto from 'crypto';

const ENCRYPTION_KEY = process.env.ENCRYPTION_KEY; // 32 bytes

function encrypt(text: string): string {
  const iv = crypto.randomBytes(16);
  const cipher = crypto.createCipheriv('aes-256-cbc', ENCRYPTION_KEY, iv);
  const encrypted = Buffer.concat([cipher.update(text), cipher.final()]);
  return iv.toString('hex') + ':' + encrypted.toString('hex');
}

function decrypt(text: string): string {
  const [ivHex, encryptedHex] = text.split(':');
  const iv = Buffer.from(ivHex, 'hex');
  const encrypted = Buffer.from(encryptedHex, 'hex');
  const decipher = crypto.createDecipheriv('aes-256-cbc', ENCRYPTION_KEY, iv);
  const decrypted = Buffer.concat([decipher.update(encrypted), decipher.final()]);
  return decrypted.toString();
}

// Utilisation
async createSource(input) {
  const encryptedConfig = {
    ...input.config,
    apiKey: encrypt(input.config.apiKey)
  };
  
  return prisma.source.create({
    data: { ...input, config: encryptedConfig }
  });
}

// 3. Audit logs
model AuditLog {
  id String @id
  userId String
  action String // 'CREATE', 'READ', 'UPDATE', 'DELETE'
  entity String // 'Mention', 'Source', etc.
  entityId String
  changes Json? // Avant/aprÃ¨s
  ipAddress String
  createdAt DateTime @default(now())
}

// Middleware d'audit
const auditMiddleware = async (req, res, next) => {
  const originalJson = res.json;
  
  res.json = function(data) {
    // Logger l'action
    prisma.auditLog.create({
      data: {
        userId: req.user.userId,
        action: req.method,
        entity: req.baseUrl,
        entityId: req.params.id,
        ipAddress: req.ip
      }
    });
    
    return originalJson.call(this, data);
  };
  
  next();
};
```

### 7.5 Risque 5 : DisponibilitÃ© (Downtime)

**ProblÃ¨me:** API indisponible = perte de donnÃ©es de scraping

**Solutions:**

```yaml
# docker-compose.prod.yml
services:
  api:
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        max_attempts: 3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  postgres:
    deploy:
      replicas: 1
    volumes:
      - postgres_data:/var/lib/postgresql/data
    # Backup automatique
    command: >
      bash -c "
        while true; do
          pg_dump -U postgres sentinelle > /backups/backup-$(date +%Y%m%d-%H%M%S).sql
          sleep 3600
        done
      "
```

```typescript
// Graceful shutdown
process.on('SIGTERM', async () => {
  logger.info('SIGTERM received, closing server gracefully');
  
  // 1. ArrÃªter d'accepter nouvelles requÃªtes
  server.close(() => {
    logger.info('HTTP server closed');
  });
  
  // 2. Terminer les jobs en cours
  await scrapingQueue.close();
  
  // 3. Fermer connexions DB
  await prisma.$disconnect();
  
  // 4. Exit
  process.exit(0);
});
```

---

## ğŸ“Š RÃ‰SUMÃ‰ EXÃ‰CUTIF

### Points Forts âœ…

1. **Architecture modulaire** bien structurÃ©e (14 modules cohÃ©rents)
2. **Authentification centralisÃ©e** avec JWT (cohÃ©rente sur tous les modules)
3. **Scraping fonctionnel** avec Scrapy (4 scrapers actifs)
4. **Base de donnÃ©es bien modÃ©lisÃ©e** (Prisma avec relations claires)
5. **SÃ©paration des responsabilitÃ©s** (API, Scrapers, AI Service)

### Points Critiques ğŸ”´

1. **Pas de workers Node.js** â†’ Scraping manuel uniquement
2. **Pas de pagination** â†’ Risque de timeout sur gros volumes
3. **Isolation des donnÃ©es incomplÃ¨te** â†’ Faille de sÃ©curitÃ©
4. **Pas de batch processing** â†’ Performance limitÃ©e
5. **Validation incohÃ©rente** â†’ Risque d'erreurs runtime

### PrioritÃ©s d'Action

| PrioritÃ© | Action | Impact | Effort |
|----------|--------|--------|--------|
| ğŸ”´ P0 | ImplÃ©menter workers BullMQ | Critique | 2j |
| ğŸ”´ P0 | Ajouter pagination partout | Critique | 1j |
| ğŸ”´ P0 | Corriger isolation des donnÃ©es | SÃ©curitÃ© | 1j |
| ğŸŸ  P1 | Batch processing scrapers | Performance | 1j |
| ğŸŸ  P1 | Validation Zod systÃ©matique | QualitÃ© | 2j |
| ğŸŸ¡ P2 | Repository pattern | MaintenabilitÃ© | 3j |
| ğŸŸ¡ P2 | Event-driven architecture | ScalabilitÃ© | 3j |

### Recommandation Finale

**L'architecture actuelle est SOLIDE pour un MVP**, mais nÃ©cessite des amÃ©liorations critiques avant la production Ã  grande Ã©chelle :

1. **Court terme (1 semaine)** : Workers + Pagination + Isolation
2. **Moyen terme (1 mois)** : Batch processing + Validation + Monitoring
3. **Long terme (3 mois)** : Read replicas + Archivage + Circuit breakers

**Verdict:** ğŸŸ¢ **Architecture viable avec corrections urgentes**

